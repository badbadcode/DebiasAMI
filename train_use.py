# -*- coding: utf-8 -*-
"""classificationUsingTFHUBandKERAS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13AFGEdCUb8C1TIpDERVo4yrcRlPtVSYT
"""

import tensorflow as tf
import tensorflow_hub as hub
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import re
import seaborn as sns
import keras
import keras.layers as layers
from keras.models import Model
from keras import backend as K
from keras import optimizers
from sklearn import metrics
from sklearn.model_selection import train_test_split
np.random.seed(10)
os.chdir("/nfsshare/home/hanmingyue/DebiasAMI/")
tf.compat.v1.disable_eager_execution()

def load_data(train_fp):
    option_list = ['id', 'text', 'misogynous', 'misogyny_category', 'target']
    train_data_df = pd.read_csv(train_fp, header=0, sep="\t", names=option_list)
    train_text = train_data_df['text'].tolist()
    train_text = [re.sub('[^A-Za-z0-9 ,\?\'\"-._\+\!/\`@=;:]+', ' ', x) for x in train_text]
    train_text = np.array(train_text, dtype=object)[:, np.newaxis]
    train_label = np.asarray(pd.get_dummies(train_data_df["misogynous"].tolist()))
    return train_text,train_label

embed = hub.load(r"resource/universal-sentence-encoder-large_5")
train_fp = "data/AMI EVALITA 2018/en_training_anon.tsv"
test_fp = "data/AMI EVALITA 2018/en_testing_labeled_anon.tsv"

train_text, train_label = load_data(train_fp)
train_text, dev_text, train_label, dev_label = train_test_split(train_text, train_label, test_size=0.2, random_state=42)
test_text, test_label = load_data(test_fp)

train_embed = embed(list(np.array(train_text).ravel()))
dev_embed = embed(list(np.array(dev_text).ravel()))
test_embed = embed(list(np.array(test_text).ravel()))


with tf.compat.v1.Session() as session:
    tf.compat.v1.keras.backend.set_session(session)
    session.run(tf.compat.v1.global_variables_initializer())
    session.run(tf.compat.v1.tables_initializer())
    train_embeded=session.run(train_embed)
    dev_embeded = session.run(dev_embed)


    model=keras.Sequential([#layers.Dense(256, activation='relu'),
                            layers.Dense(128, activation='relu'),
                            layers.Dense(64, activation='relu'),
                            layers.Dense(2, activation='softmax')])
    # adam = optimizers.Adam(lr=0.0001)
    sgd = optimizers.SGD(lr=0.0001)
    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])
    model.fit(train_embeded,train_label,epochs=50,batch_size=32,validation_data=(dev_embeded,dev_label))
    model.save_weights("saved_model/mis.h5")


# # test
# with tf.compat.v1.Session() as session:
#     tf.compat.v1.keras.backend.set_session(session)
#     session.run(tf.compat.v1.global_variables_initializer())
#     session.run(tf.compat.v1.tables_initializer())
#     test_embeded=session.run(test_embed)
#     model.load_weights("saved_model/mis.h5")
#     predicts = model.predict(test_embeded, batch_size=32)
#
#
# y_test = np.argmax(test_label, axis=1)
# y_preds = np.argmax(predicts, axis=1)
# metrics.confusion_matrix(y_test, y_preds)
# print(metrics.classification_report(y_test, y_preds))


